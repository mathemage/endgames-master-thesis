\chapter{Background, Definitions and Notations}

The field of Game Theory deals with interactions or conflicts between $2$ or more agents.
\todo

\section{General Game Theory}

\begin{itemize}
  \item players
  \item actions
  \item payoffs
  \item \emph{Nash equilibrium}
  \item \emph{best response}
\end{itemize}

\subsection{Extensive form}

An \emph{extensive-form game} consists of

\begin{itemize}
  \item a finite set of \emph{players} $P$,
  \item a finite set $H$ of all possible \emph{histories},
    \begin{itemize}
      \item Each history consists of individual \emph{actions}.
      \item $h \sqsubseteq h'$ denotes that history~$h$ is a~prefix of $h'$.
      \item $\emptyset \in H$ and $h' \in H \land h \sqsubseteq h' \implies h \in H$
      \item Set $Z \subseteq H$ is the set of \emph{terminal histories}, i.e. histories that are not prefixes of any other histories.
    \end{itemize}
  \item the set of available actions $A(h) = \braces{a: (h, a) \in H}$ for every node $h \in H \setminus Z$,
  \item a~function $p$ assigning an~\emph{acting player} to each $h \in H \setminus Z$.
    The acting players are taken from the set $P \cup c$, where $c$ is the \textbf{c}hance player (e.~g. a~dice, the card dealer, the nature etc.).
  \item a~function $f_c$ determining the probability measure over actions $A(h)$ for nodes $h$ with $p(h) = c$, the nodes of the chance player.
  \item The partition $\I_i$ of nodes $\braces{h \in H: p(h) = i}$ is called the \emph{information partition} of player~$i$.
    Its element $I \in \I_i$ is an \emph{information set} of player~$i$.
    An information set represents grouping of histories that are indistinguishable from $i$'s point of view.
    In the game of poker, for example, this might be because of hidden cards of opponents.
  \item a \emph{utility function} $u_i\colon Z \goto \R$,
\end{itemize}

There are further notions related to any extensive-form game:

\begin{itemize}
  \item \emph{strategy}~$\sigma_i$ of (non-chance) player~$i$ determines a~probability distribution over $A(I)$ at every $I \in \I_i$.
    Thus $\pi ^\sigma (I, a)$ is the probability of action $a$ at the information set~$I$.
  \item a~\emph{strategy profile} is a~vector of all (non-chance) players' strategies denoted by $\sigma = (\sigma_1, \sigma_2, \ldots, \sigma_ {\abs{P}})$.
    The set of all such possible strategy profiles is denoted by $\Sigma$.
  \item We use the Greek letter $\pi$ to evaluate the probability corresponding to a~profile~$\sigma$:
    \[\pi ^\sigma(h) = \prod _{i \in P \cup c} \pi _i ^\sigma (h)\]
    
  \item \emph{counterfactual value}
  \item \emph{counterfactual best response}
  \item \emph{counterfactual best response value}
\end{itemize}

There may be various properties, which an~extensive-form game can have.
Such a~game can:

\begin{itemize}
  \item be \emph{two-player}
  \item have \emph{perfect recall}
  \item be \emph{zero-sum}
\end{itemize}

\subsection{Sequence form}

\section{Methods of~solution}

\subsection{Linear programming}

\subsection{Learning}

\section{Subgames (endgames)}

\subsection{Previous works}
