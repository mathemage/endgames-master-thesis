\chapter{Subgame-Margin Maximization}
\label{ch:max-margin}
\epigraphLong{
  I have discovered a~truly marvellous proof of~this, which this margin is too narrow to contain.
}{Pierre de Fermat on \emph{Fermat's Last Theorem}}
\vskip -2em
\note{
  This chapter summarizes our own paper~(\cite{Moravcik2016refining}).
}

\section{Motivation and Overview}
The outline of~this chapter is:
\begin{enumerate}[(1)]
    \setlength\itemsep{-.5ex}
  \item listing the steps used by~our technique,
  \item using the problem of~refining imperfect-information subgames to motivate a~value to be maximized,
  \item formalizing this value as the \emph{\acrlong{sm}},
  \item discuss and formalize its properties,
  \item formulate an~\acrshort{lp} optimizing the \acrshort{sm},
  \item describe a~corresponding \acrshort{efg} construction: \emph{a~max-margin gadget}.
\end{enumerate}
Our technique follows the steps of~the subgame-refinement framework:
\begin{enumerate}[(i)]
    \setlength\itemsep{-.5ex}
  \item create an~abstraction for the game;
  \item compute an~equilibrium approximation within the abstraction,
  \item play according to this strategy,
  \item when the play reaches final stage of~the game, create a~fine-grained abstraction for the endgame,
  \item refine the strategy in~the fine-grained abstraction,
  \item use the resulting strategy in that subgame (creating a~combined strategy).
\end{enumerate}
Since all the steps except for (v) are identical to already described techniques, we describe only step (v) in details.

\section{Subgame Margin}
\epigraph{
  Your margin is my opportunity.
}{Jeff Bezos}
To address the potential increase in~exploitability caused by an~opponent altering his behavior in the trunk, we ensure that there is no~distribution of~starting states that would allow him to increase his CBV when confronted by subgame refinement.
The simplest way to ensure this is to decrease his CBV in~all possible starting states.
We can put a~lower bound on~this improvement by measuring the state with the smallest decrease in CBV.
Our goal is to maximize this lower bound.
We refer to this values as the \acrfull{sm}.

\begin{framed}
  \begin{defn}[\acrlong{sm}]
    Let $\sigma_1$, $\sigma_1'$ be a~pair of~player~$1$'s strategies for subgame~$S$.
    Then a~\acrlong{sm}
    \[
      SM_1 (\sigma_1, \sigma_1' , S) =
      \min_{I_2 \in \I_2^{R(S)}}
      \left( CBV_2^{\sigma_1} (I_2) - CBV_2^{\sigma_1'} (I_2) \right)
    \]
    measures the ``gap in~decrease'' between the old and the new \acrlong{cbv}s, across all root information sets $I_2 \in \I_2^{R(S)}$.
  \end{defn}
\end{framed}

Subgame margin has several useful properties.
The exploitability is strongly related to the value of~the margin:
if it is non-negative, the new combined strategy is guaranteed to be no more exploitable than the original one.
To prove it, we will first re-state Theorem~\ref{thm:cf-val-and-utility} using the following lemma:
\begin{lem}
  \label{lem:cbv-and-sm}
  $CBV_2^{\sigma_1'} (I_2) \leq CBV_2^{\sigma_1} (I_2)$ for all $I_2 \in \I_2^{R(S)}$
  iff
  $SM_1 (\sigma_1, \sigma_1' , S) \geq 0.$
\end{lem}
\begin{proof}
  $
  CBV_2^{\sigma_1'} (I_2) \leq CBV_2^{\sigma_1} (I_2)
  \quad \Longleftrightarrow \quad
  0 \leq CBV_2^{\sigma_1} (I_2) - CBV_2^{\sigma_1'} (I_2)
  \quad \Longleftrightarrow \quad
  0 \leq \min_{I_2 \in \I_2^{R(S)}} \left( CBV_2^{\sigma_1} (I_2) - CBV_2^{\sigma_1'} (I_2) \right)
  = SM_1 (\sigma_1, \sigma_1' , S)
  $
\end{proof}

\begin{cor}[Theorem~\ref{thm:cf-val-and-utility} via \acrlong{sm}]
  \label{cor:sm-and-utility}
  Given a~strategy~$\sigma_1$, a~subgame~$S$, and a~re-solved subgame strategy~$\sigma_1^S$, let $\sigma_1' = \sigma_{1, [S \leftarrow \sigma_1^S]}$ be the combination of~$\sigma_1$ and~$\sigma_1^S$.
  If $SM_1 (\sigma_1, \sigma_1' , S) \geq 0$, then $u_2(\sigma_1', \textrm{CBR}(\sigma_1')) \leq  u_2(\sigma_1, \textrm{CBR}(\sigma_1))$.
\end{cor}

Moreover, given that the opponent's \acrlong{br} reaches the subgame with non-zero probability, the exploitability of~our combined strategy is even reduced.
This improvement is at~least proportional to the subgame margin:

\begin{thm}[improvement proportional to the \acrlong{sm}]
  \label{thm:improvement-propto-sm}
  With the $S$, $\sigma_1$ and $\sigma_1'$ from the Corollary, also assume there exists a~\acrlong{br}~$\sigma_2^* = BR(\sigma_1')$ such that $\pi^{<\sigma_1',\sigma_2^*>} (I_2) > 0$ for some $I_2 \in\I_2^{R(S)}$.
  Then 
  \[
    u_1(\sigma_1', CBR(\sigma_1')) - u_1(\sigma_1, CBR(\sigma_1)) \ge \pi_{-2}^{\sigma_1'} (I_2) \cdot SM_1(\sigma_1, \sigma_1', S).
  \]
\end{thm}
\begin{proof}
  Without loss of~generality, we may assume
  \begin{enumerate}[(a)]
    \item $\sigma_2^* = CBR_2(\sigma_1')$, since we may arbitrarily change strategy in any information set~$I$ that is unreachable under $\sigma_2^*$ (i.e., where $\pi_2^{\sigma_2^*}(I) = 0$),
    \item $\pi_2^{\sigma_2^*}(I_2) = 1$, since we can choose any action from a~best-response support with probability $1$ (obvious by building a~best-response recursively bottom-up).
  \end{enumerate}
  First, we show that if $p(I) = 2$ and $I$ lies on a~path from $\emptyset$ (the root of~the whole game) to $I_2$, then
  \begin{equation}
    \label{eq:cbv-and-sm}
    CBV_2^{\sigma_1'}(I)
    \le CBV_2^{\sigma_1}(I) - \pi_{-2}^{\sigma_1'}(I \to I_2) \cdot SM_1(\sigma_1 , \sigma_1', S).
  \end{equation}
  We prove (\ref{eq:cbv-and-sm}) by~induction on~the length of~the $I \to I_2$ path (measured in~the count of~$2$'s information sets).
  For the base case $I = I_2$, the claim holds by~$\pi_{-2}^{\sigma_1'}(I_2 \to I_2) = 1$ and the definition of~the subgame margin:
  \begin{align*}
    SM_1(\sigma_1 , \sigma_1', S) = \min_{I'\in\I_2^{R(S)}} \left( CBV_2^{\sigma_1}(I') - CBV_2^{\sigma_1'}(I') \right) \le CBV_2^{\sigma_1}(I_2) - CBV_2^{\sigma_1'}(I_2) \\
  \end{align*}

  For the inductive step, let $I \ne I_2$ be an~information set from $\emptyset \to I_2$ path, let $I'$ be $2$'s next information set after~$I$ on~this path, implying $\pi_2^{<\sigma_1', \sigma_2^*>} (I \to I') = 1$, and let the action~$a\in A(I)$ lead to $I_2$, implying $\pi^{\sigma_2^*}_2(I, a) = 1$.
  We can thus re-expresses the \acrshort{cbv} in~$I$ as
  \begin{align*}
    CBV_2^{\sigma_1'}(I)
    = v_2^{<\sigma_1', \sigma_2^*>} (I, a)
    \ldots
  \end{align*}
  by the definition of~the counterfactual value and $\pi_2^{<\sigma_1', \sigma_2^*>} (I \to I') = 1$ we get
  \begin{align*}
    \ldots
    = \pi^{<\sigma_1', \sigma_2^*>}(I\to I') \cdot v_2^{<\sigma_1', \sigma_2^*>}(I')
    = \pi^{<\sigma_1', \sigma_2^*>}(I\to I') \cdot CBV_2^{\sigma_1'}(I')
    \ldots
  \end{align*}
  by inductive hypothesis we bound
  \begin{align*}
    \ldots
    &\le \pi^{<\sigma_1', \sigma_2^*>}(I \to I') \cdot \left( CBV_2^{\sigma_1'}(I') - \pi_{-2}^{\sigma_1'}(I' \to I_2) \cdot SM_1(\sigma_1 , \sigma_1', S) \right) \\
    &= \pi^{<\sigma_1', \sigma_2^*>}(I \to I') \cdot CBV_2^{\sigma_1'}(I') \\
    &- \pi^{<\sigma_1', \sigma_2^*>}(I \to I') \cdot \pi_{-2}^{\sigma_1'}(I' \to I_2) \cdot SM_1(\sigma_1 , \sigma_1', S)
    \ldots
  \end{align*}
  again by the definition of~the counterfactual value we re-write back
  \begin{align*}
    \ldots
    = v_2^{<\sigma_1, CBR(\sigma_1)>} (I, a) - \pi^{<\sigma_1', \sigma_2^*>}(I \to I') \cdot \pi_{-2}^{\sigma_1'}(I' \to I_2) \cdot SM_1(\sigma_1 , \sigma_1', S)
    \ldots
  \end{align*}
  and by $\pi_2^{<\sigma_1', \sigma_2^*>} (I \to I') = 1$ we conclude
  \begin{align*}
    \ldots
    &= v_2^{<\sigma_1, CBR(\sigma_1)>} (I, a) - \pi^{\sigma_1'}_{-2}(I \to I') \; \pi_{-2}^{\sigma_1'}(I' \to I_2) \; SM_1(\sigma_1 , \sigma_1', S) \\
    &= v_2^{<\sigma_1, CBR(\sigma_1)>} (I, a) - \pi^{\sigma_1'}_{-2}(I \to I_2) \; SM_1(\sigma_1 , \sigma_1', S) \\
    &\le \left( \max_{a'\in A(I)} v_2^{<\sigma_1, CBR(\sigma_1)>} (I, a') \right) - \pi^{\sigma_1'}_{-2}(I \to I_2) \; SM_1(\sigma_1 , \sigma_1', S) \\
    &= CBV_2^{\sigma_1}(I) - \pi^{\sigma_1'}_{-2}(I \to I_2) \; SM_1(\sigma_1 , \sigma_1', S).
  \end{align*}
  If $p(\emptyset) = 2$, then in a~zero-sum game we have $u_1(\sigma_1', CBR(\sigma_1')) = -CBV_2^{\sigma_1'}(\emptyset)$ and
  $u_1(\sigma_1, CBR(\sigma_1)) = -CBV_2^{\sigma_1}(\emptyset)$.
  Hence, applying (\ref{eq:cbv-and-sm}) to the root
  \begin{align*}
    \pi^{\sigma_1'}_{-2}(I_2) \cdot SM_1(\sigma_1 , \sigma_1', S)
    &\le CBV_2^{\sigma_1}(\emptyset) - CBV_2^{\sigma_1'}(\emptyset) \\
    &= u_1(\sigma_1', CBR(\sigma_1')) - u_1(\sigma_1, CBR(\sigma_1))
  \end{align*}
  proves the theorem.
  If $p(\emptyset) \ne 2$, then we can simply add a~new state for player~$2$ at~the beginning of~the game, where $2$ has one single action leading to~$\emptyset$.
\end{proof}
Though this lower bound might seem artificial at~first, it has promising properties for the subgame refinement.
Since we refine the strategy once we reach the subgame, either we face $2$'s \acrlong{br} that reaches $S$, or he has made a~mistake earlier in the game.

Furthermore, the probability of~player~$1$ reaching a~subgame is proportional to $\pi_{-2}^{\sigma_1'}(I_2)$.
As this term (and by extension, the bound) grows, the probability of~reaching that subgame increases.
In conclusion, we are more likely to reach a~subgame with a~larger bound.

\section{Linear Program}
To formulate the subgame-margin maximization as an~\acrshort{lp}, we easily modify (\ref{lp:cfr-d}):
\begin{equation}
  \label{lp:max-margin}
  \begin{split}
    \max_{v, x}\ &\textcolor{red}{m} \\
    v_I - m &\ge CBV_2^{\sigma_1}(I), \quad I \in \I_2^{R(S)}\\ 
    Ex &= e \\
    F^\top v - A_2^\top x &\le \vect{0} \\
    x &\ge \vect{0},
  \end{split}
\end{equation}
where $m$ is a~scalar corresponding to the subgame margin that we aim to~maximize.
It serves as ``a gap'' between all values $v_I$ and the given constants $CBV_2^\sigma(I)$, and we wish to make this gap as~large as~possible.

The similarities between (\ref{lp:max-margin}) and (\ref{lp:cfr-d}) make it easier to see our improvement:
the \acrshort{lp} (\ref{lp:cfr-d}) only guarantees a~non-negative margin, whereas we maximize it.
Although the optimization formulation is almost identical to~the re-solving, our gadget construction is different.

\section{Equivalent Gadget Game}
\epigraphLong{
  A~new gadget that lasts only five minutes is worth more than an~immortal work that bores everyone.
}{Francis Picabia}
One way to find the refined strategy is to solve the corresponding \acrfull{lp}.
However, algorithms that are tailor-made for \acrshort{efg}s often outperform the optimization approach (\cite{Bosansky2013solving}).
These algorithms often permit the use of~domain-specific tricks to provide further performance gains (\cite{Johanson2012efficient}).
Thus, formulating our optimization problem~(\ref{lp:max-margin}) as an \acrshort{efg} will mean that we can compute larger subgame abstractions using the available computing resources.
Essentially, the construction of a~gadget game equivalent to the \acrshort{lp}~(\ref{lp:max-margin}) will allow us to compute larger subgames---more than it would be possible with just the plain \acrshort{lp}.

All states in~the original subgame are directly copied into the resulting gadget game.
We create the gadget game by~making two alterations to~the original subgame:
\begin{enumerate}[(i)]
  \item we shift player~$2$'s utilities using the $CBV_2$ (to initialize all $2$'s values to~zero)
  \item we add a~rooting node~$\dt$ for $2$, followed by chance nodes $c_{I_1}, c_{I_2}, c_{I_3}, \dots$ at~the top of the subgame (to allow the opponent to~pick any starting state, relating the game values to~the margin)
\end{enumerate}

\begin{figure}[H]
  \centering
  \def\svgwidth{.4\textwidth}
  \input{../img/max-margin-gadget.pdf_tex}
  \def\captionTitle{Our max-margin gadget}
  \caption[\captionTitle]{\captionTitle. When $1$'s original strategy is used, the terminal nodes' offsets enforce the opponent to have a~zero utility in~a~\acrshort{br}.}
  \label{fig:max-margin-gadget}
\end{figure}

The following is a~description of~the steps (see also Figure~\ref{fig:max-margin-gadget} that visualizes the gadget).
\begin{enumerate}
  \item We establish a~common baseline.
    For~comparing changes in~the performance of~$2$'s root information sets, they need a~common starting point:
    the original strategy $\sigma = (\sigma_1, \sigma_2)$ with its subgame portion $\sigma_1^S$.

    For every $I \in \I_2^{R(S)}$ we subtract the opponent's original \acrlong{cbv}, setting the utility at~each terminal node~$z \in Z(I)$ to $\ut_2(\zt) := k_{\It} \cdot u_2(z) - CBV_2^{\sigma}(I)$ (see Section~\ref{sec:cfval-shifts} for detailed explanation).
    We must not forget to~update $\ut_1(\zt) = -\ut_2(\zt)$ either, as we need the game to remain zero-sum.
    Conditioned on~the original strategy $\sigma_1^S$, the shifting gives an~expected value of~$0$ to~opponent's starting states.

  \item Player~$2$ is permitted to choose his belief at~the start of~the subgame, while $1$ retains his belief from the original strategy at~the starting point of~the subgame.
    Since $2$ is aiming to~maximize $\ut_2$, he will always select the information set with the lowest margin.
    The minimax nature of~the zero-sum game motivates player~$1$ to find a~strategy maximizing this value of~the lowest margin.

    We create an~additional decision node $\dt$ for player~$2$.
    Every action corresponds to choosing an~initial information set $I\in \I_2^{R(S)}$.
    However, since an~action can lead only to a~single tree node rather than a~whole information set, we may not connect this action to state~$\dt$ directly.
    Instead, each action leads to a new chance node $c_{\It}$, where the chance distributes histories~$\htil \in \It$ based on~the probability~$\pi_{-2}^\sigma (h)$ and the normalization factor $k_{\It} = \sum_{ h \in I} \pi_{-2}^\sigma(h)$ (again, see Section~\ref{sec:cfval-shifts}).
\end{enumerate}

\section{Gadget-Game Counterfactual Values}
\label{sec:cfval-shifts}
%Let $\mathcal{I}_2^{R(S)}$ be the set of~information sets at~the root of a~subgame~$S$ and let $\sigma$ be the strategy from the original game.
%On top of that, for every information set~$I~\in~\mathcal{I}_2^{R(S)}$ we are given its \acrlong{cbv} $CBV_2^{\sigma}(I)$.
%
%We construct a~new two-player zero-sum perfect-recall ``gadget'' game $\tilde{S}$.
%First, we add a~new root node $\dt$, where the opponent chooses an~information set $I \in \mathcal{I}_2^{R(S)}$ to enter.
%Formally, this can be achieved by creating chance nodes $c_{\It}$ per each set $\It \in \mathcal{I}_2^{R(S)}$.

As soon as the opponent picks which $c_{\It}$ to enter (i.e., with which cards to enter the subgame), the chance player deals cards to us.
The corresponding probability (of~being in~state $\tilde{h}\in \It$) is
$
  \pi_c (c_{\It}, c_{\It} \cdot \tilde{h}) = \frac {\pi_{-2} ^{\sigma}(h)} {k_{\It}}
$
where normalization factor $k_{\It} = \sum_{ h \in I} \pi_{-2}^\sigma(h)$ ensures that probabilities sum to $1$ (i.e., $\sum_{\tilde{h} \in \It} \pi_c (c_{\It}, c_{\It} \cdot \tilde{h}) = 1$).
The terminal utilities need to be adjusted for it.
First, they are multiplied by the related normalization factor to cancel the effects of~the normalization.
Then they are shifted by the counterfactual values:
\begin{equation}
  \label{eq:max-margin-utilities}
  \tilde{u}_2(\zt) := k_{\It} \cdot u_2(z) - CBV_2^\sigma(I)
\end{equation}

The following lemma states that the construction shifts counterfactual values by the given (original) counterfactual values:
\begin{lem}
  \label{lem:cfv-shift}
  Let $\tilsig$ be a~subgame strategy profile and $\sigma' = \sigma_{[S \leftarrow \tilsig]}$ its extension to the original game.
  Then the gadget-game counterfactual value of~$I\in\mathcal{I}_2^{R(S)}$ is
  \[
    \tilde{v}_2 ^\tilsig(\It) = v_2 ^{\sigma'}(I) - CBV_2^\sigma(I).
  \]
\end{lem}

\begin{proof}
  A~strategy profile~$\sigma'$ defines probability distributions at each game state, and thus we get
  \begin{equation}
    \label{eq:norm-factor-expansion}
    \sum_{z\in Z(I)} \pi_{-2}^{\sigma'}(z) \cdot \pi_{2}^{\sigma'}(z[I], z)
    = \sum_{ h \in I} \pi_{-2}^{\sigma'}(h)
    = \sum_{ h \in I} \pi_{-2}^\sigma(h)
    = k_{\It}
  \end{equation}
  where the first equality is a~recursive summation of~probabilities to $1$, by induction on height.

  Therefore, we can re-write the counterfactual value in the gadget game as
  \begin{equation*}
    \begin{split}
      \tilde{v}_2^\tilsig (\It)
      &= \sum_{z\in Z(I)}
      \pi_{-2}^\tilsig(\dt, \zt) 
      \cdot \pi_{2}^\tilsig(\zt[\It], \zt)
      \cdot \tilde{u}_2(\zt)
      \\
      &= \sum_{z\in Z(I)}
      \pi_{-2}^\tilsig(\dt, \zt[\It]) \cdot \pi_{-2}^\tilsig(\zt[\It], \zt) 
      \cdot \pi_{2}^\tilsig(\zt[\It], \zt)
      \cdot \tilde{u}_2(\zt)
      \\
      &= \sum_{z\in Z(I)}
      \frac{\pi_{-2}^{\sigma}(z[I])}{k_{\It}}
      \cdot \pi_{-2}^{\tilde{\sigma}}(z[I], z)
      \cdot \pi_{2}^{\tilde{\sigma}}(z[I], z)
      \cdot \tilde{u}_2(\zt)
      \\
      &= \sum_{z\in Z(I)}
      \frac{\pi_{-2}^{\sigma}(z[I])}{k_{\It}}
      \cdot \pi^{\tilde{\sigma}}(z[I], z)
      \cdot \tilde{u}_2(\zt)
      \\
      &\stackrel{\mathclap{\mathrm{(\ref{eq:max-margin-utilities})}}} =
      \sum_{z\in Z(I)}
      \frac{\pi_{-2}^{\sigma}(z[I])}{k_{\It}}
      \cdot \pi^{\sigma'}(z[I], z)
      \cdot (k_{\It} \cdot u_2(z) - CBV_2^\sigma(I))
      \\
      &= v_2 ^{\sigma'}(I) - \sum_{z\in Z(I)}
      \frac{\pi_{-2}^{\sigma}(z[I])}{k_{\It}}
      \cdot \pi^{\sigma'}(z[I], z)
      \cdot CBV_2^\sigma(I)
      \\
      &= v_2^{\sigma'}(I) - \sum_{z\in Z(I)}
      \frac {\pi_{-2}^{\sigma'}(z) \cdot \pi_{2}^{\sigma'}(z[I], z)} {k_{\It}}
      \cdot CBV_2^\sigma(I)
      \\
      &= v_2^{\sigma'}(I)
      - CBV_2^\sigma(I) \cdot 
      \frac {\sum_{z\in Z(I)} \pi_{-2}^{\sigma'}(z) \cdot \pi_{2}^{\sigma'}(z[I], z)} {k_{\It}}
      \\
      &\stackrel{\mathclap{\mathrm{(\ref{eq:norm-factor-expansion})}}} =
      v_2 ^{\sigma'}(I) - CBV_2^\sigma(I).
      \qedhere
    \end{split}
  \end{equation*}
\end{proof}

Hence, the gadget-game counterfactual values are shifted by right offsets and Lemma~\ref{lem:cfv-shift} therefore gives into context the gadget game and \acrshort{sm} maximization:
gadget-game counterfactual values at~$\I_2^{R(S)}$ correspond to margins.
Thus, solving the gadget translates to maximizing the minimum of~margins, i.e., maximizing the \acrlong{sm}.
\begin{framed}
  \begin{cor}
    A~strategy for the max-margin gadget is a~\acrlong{ne} if and only if it is a~solution to the \acrshort{lp}~(\ref{lp:max-margin}).
  \end{cor}
\end{framed}

\section{Experimental Results}
\label{sec:max-margin-experiments}
\epigraphLong{
  If you find that you're spending almost all your time on theory, start turning some attention to practical things; it will improve your theories. If you find that you're spending almost all your time on practice, start turning some attention to theoretical things; it will improve your practice.
}{Donald Knuth}
In this section, we evaluate endgame solving (Chapter~\ref{ch:endgame-solving}), subgame re-solving (Chapter~\ref{ch:cfr-d}) and max-margin subgame refinement (this chapter) on~the safe-refinement task for a~large-scale game.
We use an~improved version of~the \emph{Nyx} agent, the second strongest participant at~the 2014 \emph{Annual Computer Poker Competition} (\acrlong{nlhe} Total Bankroll)\footnotemark{} as~the baseline strategy to be re-fined in~subgames.
\footnotetext{\href{http://www.computerpokercompetition.org/index.php/competitions/results/105-2014-results}{http://www.computerpokercompetition.org/index.php/competitions/results/105-2014-results}}

All three of~the subgame refinement techniques tested here used the same abstractions and trunk strategy.
Following (\cite{Ganzfried2015endgame}), we begin the subgame at~start of~the last round (the river).
Although we used card abstraction to compute the original trunk strategy (\cite{Schmid2015automatic, Johanson2013evaluating}), the fine-grained abstraction for the endgame is calculated \emph{without the need for card abstraction}.
This is an~improvement over the original implementation of~(\cite{Ganzfried2015endgame}), where both the trunk strategy and the refined subgame used card abstraction.
This is a~result of~the improved efficiency of~the \cfrplus algorithm (and the domain-specific speedups it enables), whereas the endgame solving of~(\cite{Ganzfried2015endgame}) used linear programming to~compute the strategy.

The original strategy uses action abstraction with up to $16$ actions in~an~information set.
While this number is relatively large compared to other participating agents, it is still well below the best-known upper bound on~the optimal strategy's  support size (\cite{Schmid2014bounding}).
The action abstraction used for the original Nyx strategy has the imperfect recall, whereas the refined subgame uses the perfect recall.
We use the same actions in~the refined subgame as in~the original strategy.

We refine only the subgames that has less than $1000$ betting sequences (after creating the fine-grained abstraction).
This is simply to speed up the experiments.
The original agent's strategy is preserved in~the trunk of~the game for both player~$1$ and player~$2$.
Once gameplay reaches the subgame (the river), we refine $1$'s strategy using each of~the three techniques.
We have run $10000$ iterations of~the \cfrplus algorithm in the corresponding gadget games, with exponential weighting to update the average strategies (\cite{Tammelin2015solving}).
Each technique was used to refine $\approx 2000$ subgames.
Figure~\ref{fig:sm-experiments} displays the average margins for the evaluated techniques.

The max-margin technique produces the optimal value, much greater than ones produced by~subgame re-solving or endgame solving (which has even negative \acrlong{sm}s).

\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{../img/sm-experiments}
  \def\captionTitle{\cfrplus iterations versus \acrshort{sm} of~refined strategies}
  \caption[\captionTitle]{\captionTitle (in milli big blinds per game).
    One big blind corresponds to 100 chips.
  }
  \label{fig:sm-experiments}
\end{figure}

Here follows the list of~$95\%$-confidence intervals after $10000$ iterations:
\begin{description}
  \item[endgame solving] ($-518.5 \pm 49.19$).
    The considerably negative margin values for the endgame solving suggest that the produced strategy may indeed be much more exploitable.

  \item[subgame re-solving] ($8.79 \pm 2.45$).
    The positive margin for re-solving demonstrates that in~spite of~no explicit construction forcing the margin to be positive, it does increase in practice. 
    Notice however that the margin is far below the optimal level.

  \item[max-margin] ($101.49 \pm 7.09$).
    This technique produces a~significantly larger subgame margin than the previous methods.
    The size of~the margin suggests the original strategy is potentially rather exploitable.
    Nevertheless, our technique can substantially decrease the exploitability (see Corollary~\ref{cor:sm-and-utility} and Theorem~\ref{thm:improvement-propto-sm}).
\end{description}
