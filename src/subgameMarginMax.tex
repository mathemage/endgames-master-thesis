\chapter{Subgame-Margin Maximization}
\label{ch:max-margin}
\epigraphLong{
  I have discovered a~truly marvellous proof of~this, which this margin is too narrow to contain.
}{Pierre de Fermat on \emph{Fermat's Last Theorem}}
\vskip -2em
\note{
  This chapter summarizes our own paper~(\cite{Moravcik2016refining}).
}

\section{Motivation and Overview}
The outline of~this chapter is:
\begin{enumerate}[(1)]
    \setlength\itemsep{-.5ex}
  \item listing the steps used by~our technique,
  \item using the problem of~refining imperfect-information subgames to motivate a~value to be maximized,
  \item formalizing this value as the \emph{\acrlong{sm}},
  \item discuss and formalize its properties,
  \item formulate an~\acrshort{lp} optimizing the \acrshort{sm},
  \item describe a~corresponding \acrshort{efg} construction: \emph{a~max-margin gadget}.
\end{enumerate}
Our technique follows the steps of~the subgame-refinement framework:
\begin{enumerate}[(i)]
    \setlength\itemsep{-.5ex}
  \item create an~abstraction for the game;
  \item compute an~equilibrium approximation within the abstraction,
  \item play according to this strategy,
  \item when the play reaches final stage of~the game, create a~fine-grained abstraction for the endgame,
  \item refine the strategy in~the fine-grained abstraction,
  \item use the resulting strategy in that subgame (creating a~combined strategy).
\end{enumerate}
Since all the steps except for (v) are identical to already described techniques, we describe only step (v) in details.

\section{Subgame Margin}
\epigraph{
  Your margin is my opportunity.
}{Jeff Bezos}
To address the potential increase in~exploitability caused by an~opponent altering his behavior in the trunk, we ensure that there is no~distribution of~starting states that would allow him to increase his CBV when confronted by subgame refinement.
The simplest way to ensure this is to decrease his CBV in~all possible starting states.
We can put a~lower bound on~this improvement by measuring the state with the smallest decrease in CBV.
Our goal is to maximize this lower bound.
We refer to this values as the \acrfull{sm}.

\begin{defn}[\acrlong{sm}]
  Let $\sigma_1$, $\sigma_1'$ be a~pair of~player~$1$'s strategies for subgame~$S$.
  Then a~\acrlong{sm}
  \[
    SM_1 (\sigma_1, \sigma_1' , S) =
    \min_{I_2 \in \I_2^{R(S)}}
    \left( CBV_2^{\sigma_1} (I_2) - CBV_2^{\sigma_1'} (I_2) \right)
  \]
  measures the ``gap in~decrease'' between the old and the new \acrlong{cbv}s, across all root information sets $I_2 \in \I_2^{R(S)}$.
\end{defn}

Subgame margin has several useful properties.
The exploitability is strongly related to the value of~the margin:
if it is non-negative, the new combined strategy is guaranteed to be no more exploitable than the original one.
To prove it, we will first re-state Theorem~\ref{thm:cf-val-and-utility} using the following lemma:
\begin{lem}
  \label{lem:cbv-and-sm}
  $CBV_2^{\sigma_1'} (I_2) \leq CBV_2^{\sigma_1} (I_2)$ for all $I_2 \in \I_2^{R(S)}$
  iff
  $SM_1 (\sigma_1, \sigma_1' , S) \geq 0.$
\end{lem}
\begin{proof}
  $
  CBV_2^{\sigma_1'} (I_2) \leq CBV_2^{\sigma_1} (I_2)
  \quad \Longleftrightarrow \quad
  0 \leq CBV_2^{\sigma_1} (I_2) - CBV_2^{\sigma_1'} (I_2)
  \quad \Longleftrightarrow \quad
  0 \leq \min_{I_2 \in \I_2^{R(S)}} \left( CBV_2^{\sigma_1} (I_2) - CBV_2^{\sigma_1'} (I_2) \right)
  = SM_1 (\sigma_1, \sigma_1' , S)
  $
\end{proof}

\begin{cor}[Theorem~\ref{thm:cf-val-and-utility} via \acrlong{sm}]
  \label{cor:sm-and-utility}
  Given a~strategy~$\sigma_1$, a~subgame~$S$, and a~re-solved subgame strategy~$\sigma_1^S$, let $\sigma_1' = \sigma_{1, [S \leftarrow \sigma_1^S]}$ be the combination of~$\sigma_1$ and~$\sigma_1^S$.
  If $SM_1 (\sigma_1, \sigma_1' , S) \geq 0$, then $u_2(\sigma_1', \textrm{CBR}(\sigma_1')) \leq  u_2(\sigma_1, \textrm{CBR}(\sigma_1))$.
\end{cor}

Moreover, given that the opponent's best response reaches the subgame with non-zero probability, the exploitability of~our combined strategy is even reduced.
This improvement is at~least proportional to the subgame margin:

\begin{thm}[improvement proportional to the \acrlong{sm}]
  \label{thm:improvement-propto-sm}
  With the $S$, $\sigma_1$ and $\sigma_1'$ from the Corollary, also assume there exists a~\acrlong{br}~$\sigma_2^* = BR(\sigma_1')$ such that $\pi^{<\sigma_1',\sigma_2^*>} (I_2) > 0$ for some $I_2 \in\I_2^{R(S)}$.
  Then 
  \[
    u_1(\sigma_1', CBR(\sigma_1')) - u_1(\sigma_1, CBR(\sigma_1)) \ge \pi_{-2}^{\sigma_1'} (I_2) \cdot SM_1(\sigma_1, \sigma_1', S).
  \]
\end{thm}
\begin{proof}
  \todo
\end{proof}
Though this lower bound might seem artificial at~first, it has promising properties for the subgame refinement.
Since we refine the strategy once we reach the subgame, either we face $2$'s \acrlong{br} that reaches $S$, or he has made a~mistake earlier in the game.

Furthermore, the probability of~player~$1$ reaching a~subgame is proportional to $\pi_{-2}^{\sigma_1'}(I_2)$.
As this term (and by extension, the bound) grows, the probability of~reaching that subgame increases.
In conclusion, we are more likely to reach a~subgame with a~larger bound.

\section{Equivalent Linear Program}
To formulate the subgame-margin maximization as an~\acrshort{lp}, we easily modify (\ref{lp:cfr-d}):
\begin{equation}
  \label{lp:max-margin}
  \begin{split}
    \max_{v, x}\ &\textcolor{red}{m} \\
    v_I - m &\ge CBV_2^\sigma(I), \quad I \in \I_2^{R(S)}\\ 
    Ex &= e \\
    F^\top v - A_2^\top x &\le \vect{0} \\
    x &\ge \vect{0},
  \end{split}
\end{equation}
where $m$ is a~scalar corresponding to the subgame margin that we aim to~maximize.
It serves as ``a gap'' between all values $v_I$ and the given constants $CBV_2^\sigma(I)$, and we wish to make this gap as~large as~possible.

The similarities between (\ref{lp:max-margin}) and (\ref{lp:cfr-d}) make it easier to see our improvement:
whereas the \acrshort{lp} (\ref{lp:cfr-d}) only guarantees a~non-negative margin, we maximize it.
Although the optimization formulation is almost identical to~the re-solving, our gadget construction is different.

\section{Gadget Game}
\epigraphLong{
  A~new gadget that lasts only five minutes is worth more than an~immortal work that bores everyone.
}{Francis Picabia}
One way to find the refined strategy is to solve the corresponding \acrfull{lp}.
However, algorithms that are tailor-made for \acrshort{efg}s often outperform the optimization approach (\cite{Bosansky2013solving}).
These algorithms often permit the use of~domain-specific tricks to provide further performance gains (\cite{Johanson2012efficient}).
Thus, formulating our optimization problem~(\ref{lp:max-margin}) as an \acrshort{efg} will mean that we can compute larger subgame abstractions using the available computing resources.
Essentially, the construction of a~gadget game equivalent to the \acrshort{lp}~(\ref{lp:max-margin}) will allow us to compute larger subgames---more than it would be possible with just the plain \acrshort{lp}.

All states in~the original subgame are directly copied into the resulting gadget game.
We create the gadget game by~making two alterations to~the original subgame:
\begin{enumerate}[(i)]
  \item we shift player~$2$'s utilities using the $CBV_2$ (to initialize all $2$'s values to~zero)
  \item we add a~rooting node~$\dt$ for $2$, followed by chance nodes $c_{I_1}, c_{I_2}, c_{I_3}, \dots$ at~the top of the subgame (to allow the opponent to~pick any starting state, relating the game values to~the margin)
\end{enumerate}

\begin{figure}[H]
  \centering
  \def\svgwidth{.4\textwidth}
  \input{../img/max-margin-gadget.pdf_tex}
  \def\captionTitle{Our max-margin gadget}
  \caption[\captionTitle]{\captionTitle. When $1$'s original strategy is used, the terminal nodes' offsets enforce the opponent to have a~zero utility in~best response.}
  \label{fig:max-margin-gadget}
\end{figure}

The following is a~description of~the steps (see also Figure~\ref{fig:max-margin-gadget} that visualizes the gadget).
\begin{enumerate}
  \item We establish a~common baseline.
    For~comparing changes in~the performance of~$2$'s root information sets, they need a~common starting point:
    the original strategy $\sigma_1^S$.

    For every $I \in \I_2^{R(S)}$ we subtract the opponent's original \acrlong{cbv}, setting the utility at~each terminal node~$z \in Z(I)$ to $\ut_2(\zt) = u_2(z) - CBV_2^{\sigma^S_1}(I)$.
    We must not forget to~update $\ut_1(\zt) = -\ut_2(\zt)$ either, as we need the game to remain zero-sum.
    Conditioned on~the original strategy $\sigma_1^S$, the shifting gives an~expected value of~$0$ to~opponent's starting states.

  \item Player~$2$ is permitted to choose his belief at~the start of~the subgame, while $1$ retains his belief from the original strategy at~the starting point of~the subgame.
    Since $2$ is aiming to~maximize $\ut_2$, he will always select the information set with the lowest margin.
    The minimax nature of~the zero-sum game motivates player~$1$ to find a~strategy maximizing this value of~the lowest margin.

    We create an~additional decision node $\dt$ for player~$2$.
    Every action corresponds to choosing an~initial information set $I\in \I_2^{R(S)}$.
    However, since an~action can lead only to a~single tree node rather than a~whole information set, we may not connect this action to state~$\dt$ directly.
    Instead, each action leads to a new chance node $c_{\It}$, where the chance distributes histories~$\htil \in \It$ based on~the probability~$\pi_{-2}^\sigma (h)$.

    \todo
\end{enumerate}

Following from the construction, we get straightforwardly
\begin{claim}
  A~strategy for the max-margin gadget is a~\acrlong{ne} if and only if it is a~solution to the \acrshort{lp}~(\ref{lp:max-margin}).
\end{claim}

\section{Experimental Results}
\label{sec:max-margin-experiments}
\epigraphLong{
  If you find that you're spending almost all your time on theory, start turning some attention to practical things; it will improve your theories. If you find that you're spending almost all your time on practice, start turning some attention to theoretical things; it will improve your practice.
}{Donald Knuth}
