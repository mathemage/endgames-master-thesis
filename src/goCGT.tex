\chapter{Go Endgames Using Ad-Hoc Mathematics}
\label{ch:goCGT}
\epigraphLong{
  Combinatorial game theory captures an~essential part of~what Go is about.
  I think that in one form or another, it will become a~key component of~all successful future Go programs.%
  \footnotemark
}{Martin~\cite{Muller1995computer}}
The ancient game of~Go offers astounding complexity:
the board size, the quantity of~possible moves and the average game length produce an~astronomical number of~valid positions.

More than in~any other classic game, human intuition plays a~vital role for a~successful play:
Go offers great richness of~geometrical, combinatorial and logical structure, ready to be exploited by human players.

Quoting Google DeepMind, the game of~Go is agreed to be ``the most challenging of~classic games for \acrlong{ai} owing to its enormous search space and the difficulty of~evaluating board positions and moves'' (\cite{Silver2016mastering}).
\footnotetext{%
  This prognosis is in fact misaligned:
  AlphaGo, the most successful Go program designed so far, uses almost no Go-specific knowledge.
  To compare \Mueller's prediction with current trends, consult the Note on page~\pageref{note:CGTvsAlphaGo} and Chapter~\ref{ch:AlphaGo}.
}
\vskip 1em
\note{
  This chapter is based on the work of Martin~\Mueller{} (\cite{Muller1995computer}) submitted as a~doctoral thesis at ETH \Zurich.
  Since the focus of~our survey are imperfect-information games rather than Go, this chapter mostly summarizes his work.
}
\vskip 1.5em
Martin~\Mueller{} reported in 1995 that (at that time) Go programs ``comprehend only the most basic concepts of~Go'' and that
``to make progress, [he~feels] it is necessary both to encode more Go-specific knowledge and to push forward the application of~theories such as \acrlong{cgt} to Go'' (\cite{Muller1995computer}).
Here follows the overview and the results of~his endeavors.

\section{Why Focus on Go Endgames?}

(\cite{Muller1995computer}) mentions the following advantages of~Go endgames for research:
\begin{itemize}
  \item The situation towards the end of~game becomes clearer.
    This simplification helps to study Go in~an easier and more controlled way.
  \item Some endgame positions allows for an~exact solution within reasonable time.
  \item Understanding parts of~board improves the understanding of~the whole game.
    Such partial evaluations aids various heuristics for solving the full board.
    Humans reason similarly: by~observing the score since the early midgame, they decide based on~such a~heuristic analysis (\cite{Takagawa85}).
  \item Methods and techniques for partitioning, searching and scoring during endgame are frequently also applicable to the midgame and opening.
  \item Endgames provide a~simplified, more manageable sub-domain allowing the use of~stronger theoretical models than the larger, more general problem.
\end{itemize}

\section{Partitioning into (Sub)games and Playing The Game-Sum}
\epigraph{
  Divide et impera.
}{Philip II of~Macedon}
A~typical Go position contains several \emph{subgames} (local scenes) suitable for independent analysis.
Initially, the subgames have no influences on~one another due to their mutual distance.
Nevertheless, as the game progresses, they gain the crucial role thanks to a~more distinct board partitioning via walls of~safe stones:
\begin{figure}[H]
  \centering
  \includegraphics[width=.4\textwidth]{../img/late_endgame_Go_position_suited_for_exact_analysis.png}
  \captionWithCite{An~immortal wall enabling an exact analysis during late endgame}{Muller1995computer}
  \label{fig:immortal-wall}
\end{figure}
No move can have any influence across these ``immortal'' walls and significant parts of~the board belong with certainty to one of the players.
The connected components of~remaining stones define local subgames independent from each other.

In the opening and midgame, partitioning can be only approximate.
On the other hand, the partitioning in the endgame becomes more precise:
the statuses of~all big groups have been settled, and the outlines of~territories are clear.
If each local game is simple enough for complete analysis (such as in Figure~\ref{fig:immortal-wall}), \acrshort{cgt} can compute an~optimal move for the full board position.

Now follows the general procedure of~(\cite{Muller1995computer}) for playing Go as a~sum of~local games:
\begin{enumerate}
  \item Board partition: find safe blocks, safe territories, and local areas.
  \item Generate local game trees in each area.
  \item Evaluate local terminal positions.
  \item Transform local game trees into combinatorial games and simplify them.
  \item Find an optimal move in the \acrshort{cgt} sum-game and play it.
\end{enumerate}
\Mueller{} proposes heuristic algorithms for playing the entire game, and exact algorithms for late endgame positions.

Undoubtedly, the task of~solving endgames in 1995 (when computer Go was at~its infancy) already played an~important role.

\section{Combinatorial Game Theory for the Game of~Go}
\epigraphLong{
  You get surreal numbers by~playing games.

  I used to feel guilty in Cambridge that I spent all day playing games, while I was supposed to be doing mathematics.
  Then, when I discovered surreal numbers, I realized that playing games is math.
}{John Conway}
(\cite{Muller1995computer}) suggests to replace the ``standard model'' of~computer Go by a~sum-game model.
Here follows some general benefits and problems of~the sum-game model for computer Go, as listed the work:

\medskip

\underline{Benefits}
\begin{itemize}[+]
  \item suitability to the knowledge and style of~Go programs (at that time):
    local fighting, surrounding territories, etc.
  \item reusing of~local game analysis for a~high-quality game play
  \item simplifying move generation and evaluation of~positions
  \item translating Go terms into the theory, without need for~separate programming
  \item evaluating opponent's endgame moves
  \item assessing sufficiently good moves even with a~\emph{reduced} local game database
  \item computing the game-theoretic value of a~position long before the end
  \item opportunities for parallelism:
    independent local searches, evaluations and operations on mathematical games, etc.
  \item perfect computer play in~late endgame
\end{itemize}

\newpage

\underline{Obstacles}
\begin{itemize}[-]
  \item required accurate board partition and dependency recognition
  \item common issues of~selective search:
    misleading evaluation due to missing crucial moves in~complicated games
  \item the lack of~long-range full-board planning:
    ``This is probably not a~big issue until programs reach amateur Dan or even professional level.''
    (\cite{Muller1995computer})
\end{itemize}

Additionally, a~strict endgame analysis is impossible, when any of~these limits is reached:
\begin{itemize}[-]
  \item \textbf{partition:}
    There is insufficient amount of~blocks that can be proven safe.
    Some of~the areas are hence too large for~the complete search.

  \item \textbf{summation:}
    No~move with dominating incentive\footnotemark{} exists, and both summing and partial search would take too long.
    \footnotetext{the improvement made by moving in a~game -- \cite[Chapter 3, p.~38]{Muller1995computer}}

  \item \textbf{Ko:}
    \acrshort{cgt} relies on the independence of~local subgames.
    In the case of~Ko, the independence is broken:
    a~locally bad move may be globally best if it serves as a~Ko threat (recall Section~\ref{sec:Go}).
    \Mueller{} mentioned in~1995 there was ongoing research to generalize the theory for handling Kos.

  \item \textbf{unneccessary complexity in ``straightforward'' situations:}
    In cases where the focus of~play is straightforward (i.e., only one local situation is relevant), \acrshort{cgt} introduces additional complexity.
    It investigates moves for~both players in~this and every other position.
\end{itemize}

\section{Board Partition and Subgame Dependencies}
\epigraphLong{
  Independence?
  That's middle class blasphemy.
  We are all dependent on~one another, every soul of~us on Earth. 
}{George Bernard Shaw}
In addition, (\cite{Muller1995computer}) mentions several further obstacles of~the sum-game model, caused by~the \emph{heuristic} board partition:

\begin{itemize}[-]
  \item \textbf{the impossibility of a~perfect precise split:}
    During the opening and mid-game, there are almost no surrounded spaces.
    Moreover, the surrounding stones would not be invulnerable yet.
    Heuristics is needed for board partition to split the imperfectly surrounded areas.

  \item \textbf{the infeasibility of~exhaustive search in still large subgames:}
    The program is obliged to give a~move in~few seconds or minutes.
    However, there still remain areas intractable for an~exhaustive search.

    In such subgames, \Mueller{} employs \emph{selective search} method.
    He limits the number of~generated moves and stops the search before reaching a~terminal position.
    For each local game, nodes to expand need to be decided and \emph{expert modules for search and evaluation} need to be selected.
    A~post-processing stage handles detected dependencies between games.

  \item \textbf{the dependencies between the resulting subgames, which arise with the previously mentioned heuristics:}
    The effect of~such dependencies differs widely.
    Often it is so small that independence is a~useful approximation.
    However, in cases when a~move works as a~\emph{double threat}, dependency analysis is crucial.

    Trivial strategies to overcome dependencies involve:
    \begin{itemize}
      \item ignoring the dependency, as if the games were independent;
      \item proving that the dependency does not affect the value of~the sum, or the play of~the sum game;
      \item merging mutually dependent local games, then re-search the combined game, possibly using previously generated information on single games;
      \item analyzing the interaction between local games, then use a~specialized theory to compute the joint game value;
    \end{itemize}
\end{itemize}

Hence, the sum-game model makes sense mostly during the endgame phase.
This general principle is as well applicable in poker:
we wait until the late stage of~the game, when there is more impact in~re-solving the reached endgames.

\section{Local Search and Evaluation in the Endgame}
\epigraphLong{
  True genius resides in~the capacity for~evaluation of~uncertain, hazardous, and conflicting information. 
}{Winston Churchill}
Once the board is partitioned, the algorithm of~(\cite{Muller1995computer}) performs following steps to convert a~Go endgame into a~combinatorial game:
\begin{enumerate}
  \item Generate local game trees:
    all legal moves are generated from both players' point of~view, with exceptions~of:
    \begin{enumerate}[(a)]
      \item \emph{pruning rules}\footnotemark{}, e.g., pruning dominated subgame trees:
        the evaluation of~nodes allows for pruning moves dominated by other moves.
        \footnotetext{analogous to \emph{policy networks} of~AlphaGo in Chapter~\ref{ch:AlphaGo}.}

        Moves with a~dominating alternative are labelled as~locally bad moves.

      \item \emph{termination rules}\footnotemark{} for static evaluation of a~position, without further tree expansion%
        \footnotetext{analogous to \emph{value network} of~AlphaGo in Chapter~\ref{ch:AlphaGo}.}
    \end{enumerate}

  \item Score local terminal positions:
    \begin{enumerate}[(a)]
      \item \emph{scoring} (Section~\ref{sec:Go}) comes in two widely accepted variants:
        \begin{enumerate}[$\diamondsuit$]
          \item Chinese variant, which counts stones and empty points belonging to either color,
          \item Japanese variant, which counts territory and prisoners.
        \end{enumerate}
        Both variants have straightforward implementation because safe stones, dead stones, territories and neutral points are known exactly in~the endgame.

      \item \emph{terminal positions} can be recognized by
        \begin{enumerate}[$\diamondsuit$]
          \item no more legal moves,
          \item no more good moves,
          \item the value of~position already known from the transposition table, pattern, or local position database.
        \end{enumerate}
        A~position is additionally considered terminal, once we can assess its value from another source.
        Such a~value can be any value in~the sense of~mathematical games.
    \end{enumerate}

  \item Evaluate local games as mathematical games.
    Explicitly, evaluate terminal positions, and back up the values in~the tree, resulting in a~mathematical-game evaluation of~each node.

    Even though the program reaches a~solved position, (\cite{Muller1995computer}) notes that a~``suicidal'' opponent may later cause great troubles, by endangering his immortal stones.
    Such an~act would violate the assumptions on~board partitioning and give rise to~new unexpected positions with a~rather complicated optimal play.

\begin{figure}[H]
  \centering
  \includegraphics[width=.7\textwidth]{../img/Go_search_tree.png}
  \captionWithCite{Local game tree with evaluation of terminal nodes}{Muller1995computer}
\end{figure}

  \item Select an~option in the resulting (abstract) sum game.

  \item Translate the chosen option from the abstract game into a~corresponding move in~Go.
    This move is taken as~the first move with sufficient incentive.
\end{enumerate}

\section{Storing Search Results into Database}
\epigraph{
  I'm blessed with very fast memorization skills, so I don't have to read it too far in advance.
}{Jaimie Alexander}
Search and analysis produce the complete description of possible endgame plays, facilitating the perfect strategy.
The results are stored in a~\emph{database of~local positions}.
Local subgames during a~live play are then matched one-to-one to a~set of~database positions.
The value of a~full board position is the sum of~local position values and the algorithm for sum-game evaluation selects the best available response.

A~version with lower memory requirements is implemented, too.
This is achieved by~saving only a~selection of~positions, and re-doing the search, in~case the subgame is missing in the database.

An~important question is what to store.
Table~\ref{tab:db-loc-games} gives some possible answers:
\begin{table}[!htbp]
  \centering
  \begin{tabular}{ |p{.45\textwidth}|p{.48\textwidth}| } 
    \hline
    \textbf{Type of database} & \textbf{Content} \\
    \hline
    Full                            & $\to$ every position discovered during exhaustive search \\
    Color-complete (Black or White) & $\to$ every position reachable by~non-dominated moves of~the color and arbitrary opponent's moves (pruned bad moves of~the color) \\
    Optimal                         & $\to$ at~least one position corresponding to~every non-dominated option of~every reachable position (guaranteed optimal play from every position in~database) \\
    Sufficiently good               & $\to$ guaranteed optimal score from a~starting position (might fail to exploit some opponent mistakes) \\
    \hline
  \end{tabular}
  \captionWithCite{Possible database variants of~local games}{Muller1995computer}
  \label{tab:db-loc-games}
\end{table}

One needs to make a~trade-off between re-computation time and storage space.
A~sensible solution is to~store only complicated moves in~the database, and re-calculate the rest when necessary.
It is a~good idea to save only the information whether a~move is locally good or bad, but discard all \emph{refutations}\footnotemark.
\footnotetext{trees proving that bad moves are inferior}
Such a~type of~database is robust against a~good opponent;
however, it suffers from a~play of a~locally bad opponent.
This~rare situation would call for the re-computation of~a~subtree in order to find a~refutation.

The number of~possible moves in an $n$-point area is approximately $2n$ ($n$ for each player), and such a~play generates an $n-1$ point area.
Thus, the size of~the game tree is approximately $2n\cdot2(n-1)\cdot \ldots \cdot2 = 2^n n!$ nodes.
Such a~combinatorial explosion makes even fairly small endgames prohibitively expensive.

\Mueller{} overcomes this hardness with a~transposition table.
A~\emph{transposition table} detects identical board positions, reducing the size of~the search space from $\approx 2^n n!$ to $3^n$ states (see the comparison in Table~\ref{tab:reduction-transp-tab}).
\begin{table}[!htbp]
  \centering
  \begin{tabular}{ |rrr| }
    \hline
    \textbf{$n$} & \textbf{$2^nn!$} & \textbf{$3^n$} \\
    \hline
    1	&	2	&	3 \\ 
    2	&	8	&	9 \\ 
    3	&	48	&	27 \\ 
    4	&	384	&	81 \\ 
    5	&	3840	&	243 \\ 
    6	&	46080	&	729 \\ 
    7	&	645120	&	2187 \\ 
    8	&	10321920	&	6561 \\ 
    9	&	185794560	&	19683 \\ 
    10	&	3715891200	&	59049 \\ 
    \hline
  \end{tabular}
  \caption{Reduction of search space by transposition table}
  \label{tab:reduction-transp-tab}
\end{table}

\section{Pattern Learning}
\epigraph{To understand is to~perceive patterns.}
{Isaiah Berlin}
Pattern recognition is a~key component of~the AlphaGo program (Chapter~\ref{ch:AlphaGo}).
Arguably, the program's success may also be attributed to learning Go patterns from human expert plays.

For comparison, (\cite{Muller1995computer}) hails computer Go as \emph{a~vehicle for research in~visual perception, machine learning and neural networks} (advocating to \cite{Wilcox79, Enderton1991golem, Stoutamire1991machine, Schraudolph1994temporal}).

Being introduced just and only to~Go rules, learning programs can typically pick up basic Go principles, such as saving a~stone from capture, and familiarize themselves with~low-level game concepts.
However, these concepts and principles have already been integrated into~other far superior \emph{expert-based programs}.

Neural networks are therefore more adapt at~playing locally good shapes, but possess no~idea when to play it (this part has changed thanks to AlphaGo).
These systems are vulnerable to other Go agents with better knowledge of~tactics.

Conclusively, (\cite{Muller1995computer}) suggests \emph{pattern matching} as a~promising means for advancements in~computer Go.

\epigraph{When patterns are broken, new worlds emerge.}
{Tuli Kupferberg}

\section{Contributions of~Combinatorial Game Theory to Go Endgames}
\epigraphLong{
  You can retire from a~job, but don't ever retire from making extremely meaningful contributions in~life.
}{Stephen Covey}
\Mueller's doctoral thesis acclaims these contributions to computer science:
\begin{itemize}
  \item ``Scientists are fascinated by problems which can be stated simply, yet are hard to solve.
    Computer Go is a~prime example.
    We have brought the divide-and-conquer approach, a~fundamental paradigm of~computer science, to bear on computer Go.''

  \item ``The application of a~sophisticated mathematical theory to computer Go provides an~example of~algorithms for a~nontrivial decomposition of a~complex problem.''
\end{itemize}

\noindent
These are contributions specific to computer Go:
\begin{itemize}
  \item ``We have implemented a~\emph{late endgame player}, a~niche where program play surpasses human play in both speed and exactness.
    We did this by applying concepts from \acrshort{cgt} to Go.
    The program plays a~wide variety of`late endgame positions perfectly.''

  \item ``We have developed algorithms for board partition and dependency analysis.''
\end{itemize}
In conclusion, the work employs a~technique of~applying an~elaborate mathematical theory (\acrshort{cgt}) to deal with endgames.
In particular, \acrshort{cgt} is used to ``connect'' individual relevant subgames, which may be solved independently.

As we will see later, the situation in the case of~Poker is slightly more delicate:
the imperfect-information property prevents us from using an~immediate divide-and-conquer approach.
Instead, we will \emph{augment} the information, by saturation with appropriate game states (Definition~\ref{defn:augm-info-set} in Section~\ref{sec:subgames-revisited}).

\note{
  \label{note:CGTvsAlphaGo}
  It is also interesting to compare the method of~(\cite{Muller1995computer}) with the modern approach of~\emph{AlphaGo}.

  The ad-hoc Go-specific knowledge is replaced with general-learning neural networks and the probabilistic \emph{Monte Carlo Tree Search} algorithm.
  Such a~combination has the capability to surpass professional human players at the highest ranks.

  What's more, this solution can be adapted to other games without substantial modifications.
  With enough data, the system can be trained without any need to imbue it with game-specific knowledge.
  Follow Chapter~\ref{ch:AlphaGo} for more details.
}
